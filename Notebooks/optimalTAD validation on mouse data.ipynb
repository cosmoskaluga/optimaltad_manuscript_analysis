{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "300e4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from itertools import repeat\n",
    "from collections import Counter\n",
    "import bioframe\n",
    "from collections import Counter\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter, AutoMinorLocator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea2c9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedgraph_extensions = ['.bedgraph', '.bedGraph', '.BedGraph', '.bg']\n",
    "bigwig_extensions = ['.bigwig', '.bigWig', '.BigWig', '.bw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcacda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeration(size, interaction_type = 'tad'):\n",
    "    if size%2 == 0:\n",
    "        dist = np.arange(size//2)\n",
    "        dist = np.concatenate([dist, dist[::-1]])\n",
    "    else:\n",
    "        dist = np.arange((size-1)//2)\n",
    "        dist = np.concatenate([dist, [size//2], dist[::-1]])\n",
    "        \n",
    "    if interaction_type == 'intertad':\n",
    "        if len(dist) > 1: dist = (dist + 1) * np.nan\n",
    "        else: dist = (dist + 1) * (-1)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def columns(first_col, second_col, start, end, resolution, interaction_type = 'tad'):\n",
    "    end  = resolution*math.ceil(end/resolution)\n",
    "    size = (end-start)/resolution\n",
    "    col1 = np.arange(start, end, resolution)\n",
    "    \n",
    "    if interaction_type != 'skip':\n",
    "        col2 = numeration(int(size), interaction_type).astype(str)\n",
    "    else:\n",
    "        col2 = np.repeat(np.nan, math.ceil(size))\n",
    "\n",
    "    first_col = np.append(first_col, col1)\n",
    "    second_col = np.append(second_col, col2)\n",
    "    return first_col, second_col.astype(str)\n",
    "\n",
    "\n",
    "def get_distances(data, length, chromosome, resolution):\n",
    "    first_col = np.array([])\n",
    "    second_col = np.array([])\n",
    "    \n",
    "    bp = 0\n",
    "    start_bin = int(data[0][1])\n",
    "    if start_bin != 0:\n",
    "        first_col, second_col = columns(first_col, second_col, bp, start_bin, resolution, interaction_type = 'skip')\n",
    "    bp = start_bin\n",
    "    \n",
    "    for row in data:\n",
    "        start_bin, end_bin = row[1], row[2]\n",
    "        if bp != start_bin:\n",
    "            first_col, second_col = columns(first_col, second_col, bp, start_bin, resolution, interaction_type = 'intertad')\n",
    "        first_col, second_col = columns(first_col, second_col, start_bin, end_bin, resolution, interaction_type = 'tad')\n",
    "        bp = end_bin\n",
    "    \n",
    "    \n",
    "    if (length > bp):\n",
    "        start, end = bp, length\n",
    "        first_col, second_col = columns(first_col, second_col, start, end, resolution, interaction_type = 'skip')\n",
    "    \n",
    "    labels = np.repeat([chromosome], len(first_col))\n",
    "    out = np.vstack((labels, first_col.astype(int), second_col))\n",
    "    return np.transpose(out)\n",
    "\n",
    "\n",
    "def nan_array_comparison(func, arr, thresh):\n",
    "    # https://stackoverflow.com/questions/47340000/how-to-get-rid-of-runtimewarning-invalid-value-encountered-in-greater\n",
    "    # by Divakar\n",
    "    bool_arr = ~np.isnan(arr)\n",
    "    bool_arr[bool_arr] = func(arr[bool_arr], thresh)\n",
    "    return bool_arr\n",
    "\n",
    "\n",
    "def equal_sizes(data, chromsize):\n",
    "    data_size = dict(Counter(data.Chr.values))\n",
    "    return data_size == chromsize\n",
    "\n",
    "\n",
    "def check_prefix(vector):\n",
    "    return [\"chr\" in chrm for chrm in vector]\n",
    "\n",
    "\n",
    "def check_chrnames(labels_config, labels):\n",
    "    if np.any(check_prefix(labels)) and not np.all(check_prefix(labels_config)):\n",
    "        labels_config = ['chr'+ chrm for chrm in labels_config]\n",
    "    elif not np.any(check_prefix(labels)) and np.all(check_prefix(labels_config)):   \n",
    "        labels_config = [chrm[3:] for chrm in labels_config]\n",
    "        \n",
    "    if set(labels_config).issubset(set(labels)):\n",
    "        chrnames = labels_config\n",
    "    elif len(set(labels).intersection(labels_config)) > 0:\n",
    "        chrnames = np.array(set(labels).intersection(labels_config))\n",
    "    else:\n",
    "        print('ERROR: Specified chromosomes are not found! Please set correct chromosome names in the configuration file.')\n",
    "        sys.exit(1)\n",
    "            \n",
    "    return chrnames\n",
    "\n",
    "\n",
    "def bin_calculation(chrdata, length, chrname, resolution):\n",
    "    df = pd.DataFrame([])\n",
    "    arr = []\n",
    "    i = 0\n",
    "    start_value = 0\n",
    "    #print(chrdata.head(10))\n",
    "    while i < length*resolution:\n",
    "        d = chrdata.loc[(chrdata.Start < i+resolution) & (chrdata.Start >= i)]\n",
    "        end_values = d.End.values\n",
    "        if len(end_values) > 0:\n",
    "            last_interval = end_values[-1] - (i+resolution)\n",
    "            nbins = (end_values[-1] - d.Start.values[0])//resolution\n",
    "            if nbins > 1:\n",
    "                last_interval = last_interval%resolution\n",
    "                new_bin = d.Score.values[-1]\n",
    "            else:\n",
    "                end_values[-1] -= last_interval\n",
    "                interval_len = end_values - d.Start.values\n",
    "                binvals = d.Score.values*interval_len/resolution\n",
    "                new_bin = np.nansum(np.append(binvals, start_value))\n",
    "                nbins = 1\n",
    "            start_value = d.Score.values[-1]*last_interval/resolution\n",
    "        \n",
    "        else:\n",
    "            new_bin = np.nan\n",
    "            if i < chrdata.Start.values[0]:\n",
    "                nbins = (chrdata.Start.values[0] - i)//resolution\n",
    "            else:\n",
    "                nbins = (length*resolution - i)//resolution\n",
    "        \n",
    "        for bin_idx in range(nbins):\n",
    "            arr.append([chrname, str(i+bin_idx*resolution), str(i+resolution*(1+bin_idx)), str(new_bin)])\n",
    "        \n",
    "        i += resolution*nbins\n",
    "    \n",
    "    arr = np.reshape(arr, (i//resolution, 4))\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def binarize_data(data, chromsize, resolution):\n",
    "    if equal_sizes(data, chromsize) != True:\n",
    "        df = pd.DataFrame([])\n",
    "        sizes = np.fromiter(chromsize.values(), dtype = int)\n",
    "        for chrname, length in zip(np.unique(data.Chr.values), sizes):\n",
    "            #print(chrname)\n",
    "            chr_data = data.loc[data.Chr == chrname]\n",
    "            arr = bin_calculation(chr_data, length, chrname, resolution)\n",
    "            #arr = []\n",
    "            #for i in np.arange(0, resolution*length, resolution):\n",
    "            #    d = chr_data.loc[(chr_data.Start < i+resolution) & (chr_data.Start >= i)]\n",
    "            #    arr.append([chrname, str(i), str(i+resolution), str(d.Score.mean(skipna=True))])\n",
    "\n",
    "            #arr = np.reshape(arr, (length, 4))\n",
    "            df = pd.concat([df, pd.DataFrame(arr)])\n",
    "        data = df\n",
    "        data.columns = ['Chr', 'Start', 'End', 'Score']\n",
    "        data.replace(['inf', '-inf'], 'nan', inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def blacklist_substraction(signal_data, bklst):\n",
    "    keys = list(bklst.columns.values)\n",
    "    i1 = signal_data.set_index(keys).index\n",
    "    i2 = bklst.set_index(keys).index\n",
    "    signal_data.loc[i1.isin(i2), 'Score'] = np.nan\n",
    "    return signal_data\n",
    "\n",
    "\n",
    "def get_bigwig_file(self, blacklist_regions):\n",
    "    import pyBigWig\n",
    "    bw = pyBigWig.open(self.path)\n",
    "    if bw.isBigWig() == False:\n",
    "        log.error('Incompatible format of ChIP-seq file!')\n",
    "        sys.exit(1)\n",
    "\n",
    "    df_chip = pd.DataFrame([])\n",
    "\n",
    "    for ch in bw.chroms().keys():\n",
    "        intervals = bw.intervals(ch)\n",
    "        df_intervals = pd.DataFrame(intervals, columns = ['Start', 'End', 'Score'])\n",
    "        chr_labels = list(repeat(ch, len(df_intervals.index)))\n",
    "        df_chr = pd.concat([pd.DataFrame(chr_labels, columns = ['Chr']), df_intervals], axis = 1)\n",
    "        if df_chip.empty:\n",
    "            df_chip = df_chr\n",
    "        else:\n",
    "            df_chip = pd.concat([df_chip, df_chr])\n",
    "\n",
    "        convert_dict = {'Chr': str, 'Start': int, 'End': int, 'Score': float}\n",
    "        df_chip = df_chip.astype(convert_dict)\n",
    "        \n",
    "\n",
    "    if self.chrnames != ['']:\n",
    "        labels = check_chrnames(self.chrnames, np.unique(df_chip.Chr))\n",
    "        #print(labels)\n",
    "        df_chip = df_chip.loc[df_chip['Chr'].isin(labels)]\n",
    "\n",
    "    df_chip = binarize_data(df_chip, self.chromsize, self.resolution)\n",
    "\n",
    "    return blacklist_substraction(df_chip, blacklist_regions)\n",
    "\n",
    "\n",
    "def get_bedgraph(self, blacklist_regions):\n",
    "    df_chip = pd.read_csv(self.path, sep = '\\t', comment = 't', header = None, names = ['Chr', 'Start', 'End', 'Score'])\n",
    "\n",
    "    if self.chrnames != ['']:\n",
    "        labels = check_chrnames(self.chrnames, np.unique(df_chip.Chr))\n",
    "        df_chip = df_chip.loc[df_chip['Chr'].isin(labels)]\n",
    "\n",
    "    df_chip = df_chip.replace('NA', 'nan')\n",
    "    df_chip.replace(['inf', '-inf'], 'nan', inplace=True)\n",
    "\n",
    "    df_chip = binarize_data(df_chip, self.chromsize, self.resolution)\n",
    "    convert_dict = {'Chr': str, 'Start': int, 'End': int, 'Score': float}\n",
    "    df_chip = df_chip.astype(convert_dict)\n",
    "\n",
    "    return blacklist_substraction(df_chip, blacklist_regions)\n",
    "\n",
    "\n",
    "class ChipSeq:\n",
    "    def __init__(self, path, set_chromosomes, chromsize, resolution):\n",
    "        self.path = path\n",
    "        self.extension = os.path.splitext(path)[1]\n",
    "        self.chromsize = chromsize\n",
    "        self.resolution = resolution\n",
    "        print(self.path)\n",
    "\n",
    "        if set_chromosomes != 'None':\n",
    "            self.chrnames = set_chromosomes\n",
    "        else:  \n",
    "            self.chrnames = ['']\n",
    "\n",
    "        accepted_extensions = bedgraph_extensions + bigwig_extensions\n",
    "        if self.extension not in accepted_extensions:\n",
    "            print('Incompatible format of ChIP-seq file!')\n",
    "            sys.exit(1)\n",
    "\n",
    "    def __call__(self, log2_chip, zscore_chip, blacklist_regions):\n",
    "        if self.extension in bedgraph_extensions:\n",
    "            df_chip = get_bedgraph(self, blacklist_regions)\n",
    "        else:\n",
    "            df_chip = get_bigwig_file(self, blacklist_regions)\n",
    "        \n",
    "        \n",
    "        score = df_chip.Score.values.astype(float)\n",
    "        bool_arr = nan_array_comparison(np.less, score, 1e-10)\n",
    "        score[bool_arr] = np.nan\n",
    "        df_chip.Score = score\n",
    "        \n",
    "        if log2_chip:\n",
    "            score = df_chip.Score.values\n",
    "            df_chip.Score = np.log2(score)\n",
    "            df_chip = df_chip.replace(np.inf, np.nan)\n",
    "        \n",
    "        if zscore_chip:\n",
    "            df_chip.Score = (df_chip.Score - df_chip.Score.mean()) / df_chip.Score.std(ddof=0)\n",
    "\n",
    "        return df_chip\n",
    "\n",
    "     \n",
    "    \n",
    "def get_stairs(index_data, chip_data, index_min = 0, index_max = 6, acetyl_min = -3, acetyl_max = 5, mammals = False):\n",
    "    kb_list = np.arange(index_min, index_max, 1)\n",
    "    gamma_range = index_data.keys()\n",
    "    dict_amplitudes = {key: None for key in gamma_range}\n",
    "    dict_stairs = {key: None for key in gamma_range}\n",
    "    convert_chip = {'Chr': str, 'Start': int, 'End': int, 'Score': float}\n",
    "    convert_dist = {'Chr': str, 'Bp': int, 'Index': str}\n",
    "    \n",
    "    for gamma in gamma_range:\n",
    "        df_dist = pd.DataFrame(index_data[gamma][0], columns = ['Chr', 'Bp', 'Index'])\n",
    "        chromosomes = index_data[gamma][1]\n",
    "        \n",
    "        df_dist = df_dist.loc[df_dist['Chr'].isin(chromosomes)]\n",
    "        df_chip = chip_data.loc[chip_data['Chr'].isin(chromosomes)]\n",
    "        \n",
    "        df_dist = df_dist.astype(convert_dist)\n",
    "        df_chip = df_chip.astype(convert_chip)\n",
    "        \n",
    "        df_dist = df_dist.sort_values(by = [\"Chr\", \"Bp\"])\n",
    "        df_chip = df_chip.sort_values(by = [\"Chr\", \"Start\"])\n",
    "        \n",
    "        df_dist.index = np.arange(df_dist.shape[0])\n",
    "        df_chip.index = np.arange(df_chip.shape[0])\n",
    "        \n",
    "        median_val = []\n",
    "        interTAD = []\n",
    "        TAD = []\n",
    "            \n",
    "        for idx in kb_list:\n",
    "            row = df_dist.loc[df_dist.Index == str(idx)]\n",
    "            if row.empty == False:\n",
    "                bins = row.index.values\n",
    "                d_chip = df_chip.loc[df_chip.index.isin(bins)]\n",
    "                acetyl_val = d_chip['Score'].values\n",
    "                acetyl_val = acetyl_val[~np.isnan(acetyl_val)]\n",
    "                acetyl_val = acetyl_val[(acetyl_val > acetyl_min) & (acetyl_val < acetyl_max)]\n",
    "                if len(acetyl_val) == 0:\n",
    "                    median_val.append(np.nan)\n",
    "                else:\n",
    "                    median_val.append(np.median(acetyl_val))\n",
    "                \n",
    "                if idx < 1:\n",
    "                    interTAD = np.append(interTAD, acetyl_val)\n",
    "                if idx >= 1:\n",
    "                    TAD = np.append(TAD, acetyl_val)\n",
    "            else:\n",
    "                median_val.append(np.nan)\n",
    "        \n",
    "        amplitude = np.median(interTAD) - np.median(TAD)\n",
    "        dict_stairs[gamma] = np.array(median_val)\n",
    "        dict_amplitudes[gamma] = amplitude\n",
    "    \n",
    "    return dict_stairs, dict_amplitudes\n",
    "\n",
    "\n",
    "def stylize_axes(ax):\n",
    "    ax.yaxis.major.formatter._useMathText = True\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "\n",
    "def plotAmplitude(data, output_path = 'amplitude.png', dpi = 200):\n",
    "    sns.set_palette(sns.color_palette('Set1'))\n",
    "    samples = data.columns[1:]\n",
    "    x_val = data.Gamma.values\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    for sample in samples:\n",
    "        y_val = data[sample].values\n",
    "        ax.plot(x_val, y_val, linewidth = 2.5, ls='--', color = 'steelblue', marker='o', label = sample)\n",
    "\n",
    "    ax.set_xlabel('Window size', fontsize = 20)\n",
    "    ax.set_ylabel('Amplitude', fontsize = 20)\n",
    "    ax.legend(frameon=False, fontsize = 12)\n",
    "    stylize_axes(ax)\n",
    "    ax.grid(linestyle=':', linewidth='0.2', color='black')\n",
    "    \n",
    "    if output_path:\n",
    "        path = os.path.dirname(output_path)\n",
    "        if not os.path.exists(path) and path != '':\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        ax.figure.savefig(output_path, dpi=dpi, bbox_inches='tight')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plotStair(stair_df, index_min = -5, index_max = 5, output_path = 'stair.png', dpi = 200, path_to_stair_dataframe = None):\n",
    "    sns.set_palette(sns.color_palette('Set1'))\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    for name in list(stair_df.keys()):\n",
    "        x_val = np.arange(index_min, index_max, 1)\n",
    "        y_val = stair_df[name].values\n",
    "    \n",
    "        if np.isnan(y_val).any() == True:\n",
    "            idx = np.argwhere(np.isnan(y_val))\n",
    "            idx = np.concatenate(idx)\n",
    "            x_val = np.delete(x_val, idx)\n",
    "            y_val = np.delete(y_val, idx)\n",
    "    \n",
    "        poly = np.polyfit(x_val, y_val, 3)\n",
    "        poly_y = np.poly1d(poly)(x_val)\n",
    "        ax.plot(x_val, y_val, linewidth = 2.5, color = 'steelblue')\n",
    "        #ax.plot(x_val, poly_y, linewidth = 2.5, color = 'steelblue')\n",
    "\n",
    "    ax.set_xlabel('Distance to TAD boundary, kb', fontsize = 20)\n",
    "    ax.set_ylabel('Median z-score of acetylation values', fontsize = 20)\n",
    "    ax.grid(linestyle=':', linewidth='0.2', color='black')\n",
    "    \n",
    "    stylize_axes(ax)\n",
    "    ax.legend(frameon = False, fontsize = 12)\n",
    "\n",
    "    if output_path:\n",
    "        path = os.path.dirname(output_path)\n",
    "        if not os.path.exists(path) and path != '':\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        ax.figure.savefig(output_path, dpi=dpi, bbox_inches='tight')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3009001",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 20000\n",
    "manual_chr_selection = False\n",
    "chr_to_take = ['chr1', 'chr2', 'chr3']\n",
    "log2_chip = True\n",
    "zscore_chip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4c6e4",
   "metadata": {},
   "source": [
    "## Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa63d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-cc6333796572>:1: DtypeWarning: Columns (0,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ins = pd.read_csv(os.path.join(os.path.realpath('..'),\n"
     ]
    }
   ],
   "source": [
    "ins = pd.read_csv(os.path.join(os.path.realpath('..'), \n",
    "                               '../../../../HiC_data/optimalTAD_mammals/Data/20K/Neurons/true_mouse_sampled_neurons_table_20K.txt'), sep=\"\\t\")\n",
    "names = ins['chrom'].values\n",
    "names = np.char.array(np.repeat('chr', len(names))) + np.char.array(names.astype(str))\n",
    "ins['chrom'] = names\n",
    "\n",
    "chr_names = np.unique(ins.chrom)\n",
    "\n",
    "chr_names = [x for x in chr_names if \"_\" not in x ]\n",
    "chr_names = [x for x in chr_names if \"M\" not in x ]\n",
    "chr_names = [x for x in chr_names if \"Y\" not in x ]\n",
    "chr_names = [x for x in chr_names if \"X\" not in x ]\n",
    "\n",
    "if manual_chr_selection:\n",
    "    chr_names = chr_to_take\n",
    "    \n",
    "chr_sizes = [max(ins[ins.chrom == x].end.values) for x in chr_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e838c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sizes = [i for i in ins.columns if i.find('is_boundary') == 0]\n",
    "\n",
    "for size in list_of_sizes:\n",
    "    ins.loc[(ins[size] == True) & (ins[f\"is_bad_bin\"] == True), size] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170efacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = ins.loc[ins.is_bad_bin == True, [\"chrom\", \"start\", \"end\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d68b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist.columns = ['Chr', 'Start', 'End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f8c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [i.split(\"_\")[2] for i in ins.columns if i.find('is_boundary') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "356cdfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_files = dict()\n",
    "#ins = ins[ins[f\"is_bad_bin\"] == False]\n",
    "for window_size in window_sizes:\n",
    "    ins_ws = ins[ins[f\"is_boundary_{window_size}\"] == False]\n",
    "    tads = bioframe.merge(ins_ws)\n",
    "    tads = tads[(tads[\"end\"] - tads[\"start\"]) <= 2000000].reset_index(drop=True)\n",
    "    tads = tads[['chrom', 'start', 'end']]\n",
    "    tads.columns = ['Chr', 'Start', 'End']\n",
    "    if manual_chr_selection:\n",
    "        tads = tads.loc[tads['Chr'].isin(chr_to_take)]\n",
    "    tad_files[window_size] = tads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5af622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_md = {key: [] for key in tad_files.keys()}\n",
    "df = pd.DataFrame()\n",
    "d = tad_files['60000']\n",
    "lbl_total = chr_names\n",
    "a1= get_distances(d.loc[d['Chr'] == chr_names[0]].values, chr_sizes[0], chr_names[0], resolution)\n",
    "\n",
    "\n",
    "dict_md = {key: [] for key in tad_files.keys()}\n",
    "for window_size in tad_files.keys():\n",
    "    df = pd.DataFrame()\n",
    "    d = tad_files[window_size]\n",
    "    lbl_total = chr_names\n",
    "    for length, label in zip(chr_sizes, chr_names):\n",
    "        markdown = get_distances(d.loc[d['Chr'] == label].values, length, label, resolution)\n",
    "        df_chr = pd.DataFrame(markdown)\n",
    "        df = pd.concat([df, df_chr])\n",
    "    \n",
    "    dict_md[window_size].append(df.values)\n",
    "    dict_md[window_size].append(lbl_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55673903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype = 'ACC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21600bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_signals = os.path.join(os.path.realpath('..'), '../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dbf95e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-H3K79ME3_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-MC_not20K_notdivided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-H3K27AC_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-H3K4ME1_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-CTCF_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-H3K4ME3_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/ACC-NEU-H3K27ME3_20K_divided_by_input.bw\n"
     ]
    }
   ],
   "source": [
    "for chipseq_path in glob.glob(path_to_signals+ctype+\"*bw\"):\n",
    "    ChipSeqLoader = ChipSeq(chipseq_path, chr_names, dict(Counter(dict_md['80000'][0][:,0])), resolution)\n",
    "    chip_data = ChipSeqLoader(log2_chip, zscore_chip, blacklist)\n",
    "    stairs, amplitudes = get_stairs(dict_md, chip_data, index_min = -1, index_max = 80, acetyl_min = -10, acetyl_max = 10, mammals = True)\n",
    "    suffix = chipseq_path.split('/')[-1]\n",
    "    df_sample = pd.DataFrame(amplitudes.items(), columns = ['Gamma', suffix.split('.')[0]])\n",
    "    df_sample.Gamma = df_sample.Gamma.astype(int)\n",
    "    df_sample = df_sample.sort_values(by=['Gamma'])\n",
    "    stair_dict = {}\n",
    "    stair_dict[suffix.split('.')[0]] = stairs['60000']\n",
    "    stair_df = pd.DataFrame(stair_dict)\n",
    "    suffix = chipseq_path.split('/')[-1]\n",
    "    \n",
    "    path_short = chipseq_path.split('/')[-1].split('.')[0]\n",
    "    path_short = path_short.split('-')[2].split('_')[0]\n",
    "    path_to_amplitudes = \"../Output/Neurons/20K/\"+path_short+\"/Amplitudes_\"+path_short+\".csv\"\n",
    "    path_to_stairs = \"../Output/Neurons/20K/\"+path_short+\"/Stairs_\"+path_short+\".csv\"\n",
    "    \n",
    "    #Uncomment the lines below to save the output \n",
    "    #df_sample.to_csv(path_to_amplitudes, header = True, index=True)\n",
    "    #stair_df.to_csv(path_to_stairs, header = True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0f909",
   "metadata": {},
   "source": [
    "## Glia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b181f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-f34edf0cbc07>:1: DtypeWarning: Columns (0,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ins = pd.read_csv(os.path.join(os.path.realpath('..'),\n"
     ]
    }
   ],
   "source": [
    "ins = pd.read_csv(os.path.join(os.path.realpath('..'), \n",
    "                               '../../../../HiC_data/optimalTAD_mammals/Data/20K/Glia/true_mouse_glia_table_20K.txt'), sep=\"\\t\")\n",
    "                               \n",
    "names = ins['chrom'].values\n",
    "names = np.char.array(np.repeat('chr', len(names))) + np.char.array(names.astype(str))\n",
    "ins['chrom'] = names\n",
    "\n",
    "chr_names = np.unique(ins.chrom)\n",
    "\n",
    "chr_names = [x for x in chr_names if \"_\" not in x ]\n",
    "chr_names = [x for x in chr_names if \"M\" not in x ]\n",
    "chr_names = [x for x in chr_names if \"Y\" not in x ]\n",
    "chr_names = [x for x in chr_names if \"X\" not in x ]\n",
    "\n",
    "if manual_chr_selection:\n",
    "    chr_names = chr_to_take\n",
    "    \n",
    "chr_sizes = [max(ins[ins.chrom == x].end.values) for x in chr_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e964d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sizes = [i for i in ins.columns if i.find('is_boundary') == 0]\n",
    "\n",
    "for size in list_of_sizes:\n",
    "    ins.loc[(ins[size] == True) & (ins[f\"is_bad_bin\"] == True), size] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fbd398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = ins.loc[ins.is_bad_bin == True, [\"chrom\", \"start\", \"end\"]]\n",
    "blacklist.columns = ['Chr', 'Start', 'End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf9c74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [i.split(\"_\")[2] for i in ins.columns if i.find('is_boundary') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20e1d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_files = dict()\n",
    "#ins = ins[ins[f\"is_bad_bin\"] == False]\n",
    "for window_size in window_sizes:\n",
    "    ins_ws = ins[ins[f\"is_boundary_{window_size}\"] == False]\n",
    "    tads = bioframe.merge(ins_ws)\n",
    "    tads = tads[(tads[\"end\"] - tads[\"start\"]) <= 2000000].reset_index(drop=True)\n",
    "    tads = tads[['chrom', 'start', 'end']]\n",
    "    tads.columns = ['Chr', 'Start', 'End']\n",
    "    if manual_chr_selection:\n",
    "        tads = tads.loc[tads['Chr'].isin(chr_to_take)]\n",
    "    tad_files[window_size] = tads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7bcc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_md = {key: [] for key in tad_files.keys()}\n",
    "df = pd.DataFrame()\n",
    "d = tad_files['60000']\n",
    "lbl_total = chr_names\n",
    "a1= get_distances(d.loc[d['Chr'] == chr_names[0]].values, chr_sizes[0], chr_names[0], resolution)\n",
    "\n",
    "\n",
    "dict_md = {key: [] for key in tad_files.keys()}\n",
    "for window_size in tad_files.keys():\n",
    "    df = pd.DataFrame()\n",
    "    d = tad_files[window_size]\n",
    "    lbl_total = chr_names\n",
    "    for length, label in zip(chr_sizes, chr_names):\n",
    "        markdown = get_distances(d.loc[d['Chr'] == label].values, length, label, resolution)\n",
    "        df_chr = pd.DataFrame(markdown)\n",
    "        df = pd.concat([df, df_chr])\n",
    "    \n",
    "    dict_md[window_size].append(df.values)\n",
    "    dict_md[window_size].append(lbl_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59c986d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype = 'NON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa7b489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_signals = os.path.join(os.path.realpath('..'), '../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9d0803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/NON-NEU-H3K4ME1_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/NON-NEU-H3K27AC_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/NON-NEU-H3K27ME3_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/NON-NEU-H3K79ME3_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/NON-NEU-H3K4ME3_20K_divided_by_input.bw\n",
      "/Users/dmitriismirnov/Dropbox/Projects/optimalTAD/JupyterNotebooks/../../../../HiC_data/optimalTAD_mammals/Data/aggregation_new/NON-NEU-MC_not20K_notdivided_by_input.bw\n"
     ]
    }
   ],
   "source": [
    "for chipseq_path in glob.glob(path_to_signals+ctype+\"*bw\"):\n",
    "    ChipSeqLoader = ChipSeq(chipseq_path, chr_names, dict(Counter(dict_md['80000'][0][:,0])), resolution)\n",
    "    chip_data = ChipSeqLoader(log2_chip, zscore_chip, blacklist)\n",
    "    stairs, amplitudes = get_stairs(dict_md, chip_data, index_min = -1, index_max = 80, acetyl_min = -10, acetyl_max = 10, mammals = True)\n",
    "    suffix = chipseq_path.split('/')[-1]\n",
    "    df_sample = pd.DataFrame(amplitudes.items(), columns = ['Gamma', suffix.split('.')[0]])\n",
    "    df_sample.Gamma = df_sample.Gamma.astype(int)\n",
    "    df_sample = df_sample.sort_values(by=['Gamma'])\n",
    "    stair_dict = {}\n",
    "    stair_dict[suffix.split('.')[0]] = stairs['80000']\n",
    "    stair_df = pd.DataFrame(stair_dict)\n",
    "    suffix = chipseq_path.split('/')[-1]\n",
    "    \n",
    "    path_short = chipseq_path.split('/')[-1].split('.')[0]\n",
    "    path_short = path_short.split('-')[2].split('_')[0]\n",
    "    path_to_amplitudes = \"../Output/Glia/20K/\"+path_short+\"/Amplitudes_\"+path_short+\".csv\"\n",
    "    path_to_stairs = \"../Output/Glia/20K/\"+path_short+\"/Stairs_\"+path_short+\".csv\"\n",
    "    \n",
    "    #Uncomment the lines below to save the output \n",
    "    #df_sample.to_csv(path_to_amplitudes, header = True, index=True)\n",
    "    #stair_df.to_csv(path_to_stairs, header = True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a82a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
